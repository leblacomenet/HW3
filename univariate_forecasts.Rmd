---
title: "Univariate Forecasts"
output: html_notebook
---

In this part we evaluate univariate forecasts of the gas consumption.

### Load the data
```{r}
library(readr)
gas <- na.omit(read_csv("data/gas.csv", col_types = cols(date = col_date(format = "%Y-%m-%d"))))
```

### Stationarity and integration
```{r}
library(forecast)
library(fpp)
tsdisplay(gas$log_gas_cons,main="Log transform of Gas Consumption")
tsdisplay(diff(gas$log_gas_cons, 3), main="Third Order Differientiation")
tsdisplay(diff(gas$log_gas_cons, 12), main="Twelfth Order Differientiation")
```
Unsurprisingly, we notice a strong seasonality, still observable after seasonal differencing. Exploring further the dynamics of the log consumption with annual differencing yields a time series that looks stationary.

### Models evaluation
Let us convert data to a time series
```{r}
lgas = ts(gas$log_gas_cons, start = c(1973, 1), frequency=12)
train = window(lgas, start = c(1973, 1), end = c(2015, 6))
test = window(lgas, start = c(2015,7), end = c(2016, 6))
```

We would like to evaluate models using a rolling window. Let us look at what R suggests:

## Time Series Decomposition

Let's try to decompose our series in three components: trend, seasonality and error. We assume seasonality is fixed across years and we do our analysis on the log of consumption data to avoid overweighing extreme values. This is a strong assumption that is equivalent to doing a multiplicative decomposition.

```{r}
decomp = stl(train, s.window="periodic")
plot(decomp)
```

The stl decomposition seems to capture well the seasonality "graphically". We'll see how well this translates into forecasts. Our first attempt will just forecast the time series by removing seasonality, and then using the last observation to which we add back the seasonality as the next forecast value.

```{r}
stlfk_naive = forecast(decomp, method="naive", h=12)
summary(stlfk_naive)
accuracy(stlfk_naive, test)
```

Let's try with exponential smoothing to forecast the seasonally-adjusted series.

```{r}
stlfk_ets = forecast(decomp, method="ets", h=12)
summary(stlfk_ets)
accuracy(stlfk_ets, test)
```

It actually does worse than the naive technique. As a last attempt, we can also use arima on the seasonally-adjusted data.

```{r}
stlfk_arima = forecast(decomp, method="arima", h=12)
summary(stlfk_arima)
accuracy(stlfk_arima, test)
```

R picked an ARIMA(3,1,2). The results aren't as good as with the naive approach either. To conclude on this approach, it seems that the best model is to do a naive forecast on the seasonally-adjusted data.

## Seasonal ARIMA

### Auto Arima
```{r}
autofit = auto.arima(train, seasonal=TRUE)
print(autofit)
autofk = forecast(autofit,h=12)
accuracy(autofk,test)
```

Let us now try with our own seasonal ARIMA. Based on the ACF PACF of the annual differentiation, we try with an  ARIMA(4,0,1)(0,1,2).

### Custom Seasonal Arima
```{r}
custfit = Arima(train, order=c(4,0,1), seasonal=c(0,1,2), lambda=0)
print(custfit)
custfk = forecast(custfit,h=12)
accuracy(custfk,test)
```

Although the statistical tests and criterion seem better here, the error on train and test sets are higher, so we keep the auto ARIMA.

### Rolling Window Evaluation
To try more model, we would like to setup a rolling window. Let us find the optimal size of that window using the Auto ARIMA we just fitted.
```{r}
library(ggplot2)
err = data.frame("RMSE" = rep(0, 2010-1973+1), row.names = seq(1973, 2010))
for (y in 1973:2010){
    model = Arima(window(train, start=c(y,1)), order=c(2,0,0), seasonal=c(1,1,1), include.drift = TRUE)
    rmse = accuracy(forecast(model, h=12),test)[2,"RMSE"]
    err[as.character(y),] = rmse
}
ggplot(err)+geom_line(aes(x=as.numeric(row.names(err)), y=RMSE))
```

Let us take a closer look at the year 2000.

```{r}
errm = data.frame("RMSE" = rep(0, 12), row.names = seq(1, 12))
for (m in 1:12){
    model = Arima(window(train, start=c(2000,m)), order=c(2,0,0), seasonal=c(1,1,1), include.drift = TRUE)
    rmse = accuracy(forecast(model, h=12),test)[2,"RMSE"]
    errm[as.character(m),] = rmse
}
ggplot(errm)+geom_line(aes(x=as.numeric(row.names(errm)), y=RMSE))+scale_x_continuous(breaks=seq(1,12))
```

We will thus use a rolling window of 15 full years.


